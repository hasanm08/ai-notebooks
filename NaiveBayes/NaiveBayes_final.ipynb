{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasanm08/ai-notebooks/blob/main/NaiveBayes_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z53lx-oNUG0r"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkncl81fM3FO",
        "outputId": "04a36388-217b-4caf-b57b-05af167dc0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-12-14 20:18:52--  https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84188 (82K) [application/x-httpd-php]\n",
            "Saving to: ‘sentiment labelled sentences.zip.1’\n",
            "\n",
            "sentiment labelled  100%[===================>]  82.21K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-12-14 20:18:52 (643 KB/s) - ‘sentiment labelled sentences.zip.1’ saved [84188/84188]\n",
            "\n",
            "Archive:  /content/sentiment labelled sentences.zip\n",
            "replace sentiment labelled sentences/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip\n",
        "!unzip '/content/sentiment labelled sentences.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvCk9KfiUJHQ"
      },
      "source": [
        "## Tokenization and cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4tWPecSL-yq",
        "outputId": "17b61a48-e15e-46e6-cfb2-f7219c78d801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRJA-TzxL3i7"
      },
      "outputs": [],
      "source": [
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "import random\n",
        "def clean_text(file_path):\n",
        "    with open(file_path) as f:\n",
        "      texts = f.readlines()\n",
        "    x=[]\n",
        "    y=[]\n",
        "    for text in texts:\n",
        "      y.append(int((text.split('\\t')[1]).replace(\"\\n\",\"\")))\n",
        "      tokens = word_tokenize(text)\n",
        "      # Remove the punctuations\n",
        "      tokens = [word for word in tokens if word.isalpha()]\n",
        "      # Lower the tokens\n",
        "      tokens = [word.lower() for word in tokens]\n",
        "      # Remove stopword\n",
        "      tokens = [word for word in tokens if not word in stopwords.words(\"english\")]\n",
        "      # Lemmatize\n",
        "      lemma = WordNetLemmatizer()\n",
        "      tokens = [lemma.lemmatize(word, pos = \"v\") for word in tokens]\n",
        "      tokens = [lemma.lemmatize(word, pos = \"n\") for word in tokens]\n",
        "      x.append(tokens)\n",
        "    x_train=x[int(0.8*len(x)):]\n",
        "    y_train=y[int(0.8*len(y)):]\n",
        "    x_test=x[:int(0.2*len(x))]\n",
        "    y_test=y[:int(0.2*len(y))]\n",
        "    return x_train,y_train,x_test,y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV1-IviAMaB-"
      },
      "outputs": [],
      "source": [
        "imdb_x_train,imdb_y_train,imdb_x_test,imdb_y_test= clean_text('/content/sentiment labelled sentences/imdb_labelled.txt')\n",
        "amazon_x_train,amazon_y_train,amazon_x_test,amazon_y_test=clean_text('/content/sentiment labelled sentences/amazon_cells_labelled.txt')\n",
        "yelp_x_train,yelp_y_train,yelp_x_test,yelp_y_test=clean_text('/content/sentiment labelled sentences/yelp_labelled.txt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88hmqdOJT8iV"
      },
      "source": [
        "## dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7vMRy3pUdsE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "def get_count_df(X, y):\n",
        "  from collections import defaultdict\n",
        "\n",
        "  positive_dic = defaultdict(int)\n",
        "  negative_dic = defaultdict(int)\n",
        "\n",
        "  # Count each word in every sentence\n",
        "  for sentence, label in zip(X, y):\n",
        "    # If the sentence's label is 0 increment it's count_neg\n",
        "    if label==0:\n",
        "      for word in sentence:\n",
        "        negative_dic[word]+=1\n",
        "\n",
        "    # If the sentence's label is 1 increment it's count_pos\n",
        "    if label==1:\n",
        "      for word in sentence:\n",
        "        positive_dic[word]+=1\n",
        "\n",
        "  # Convert dicts to dataframes\n",
        "  df_pos = pd.DataFrame({\"word\":positive_dic.keys(), \"count_pos\":positive_dic.values()})\n",
        "  df_neg = pd.DataFrame({\"word\":negative_dic.keys(), \"count_neg\":negative_dic.values()})\n",
        "  \n",
        "  # Join dataframes\n",
        "  df = pd.merge(df_pos, df_neg, on='word', how='outer')\n",
        "  \n",
        "  # Sort df\n",
        "  df = df.sort_values(by=[\"count_pos\",\"count_neg\"], ascending=False)\n",
        "\n",
        "  df = df.fillna(0)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw9vseBbYK6f"
      },
      "outputs": [],
      "source": [
        "def probability(word, df):\n",
        "  # calculate totals\n",
        "  total_pos = df[\"count_pos\"].sum()\n",
        "  total_neg = df[\"count_neg\"].sum()\n",
        "  total = total_pos + total_neg\n",
        "  p_pos=(total_pos)/(total)\n",
        "  p_neg=(total_neg)/(total)\n",
        "\n",
        "  # get counts for 'word'\n",
        "  pos = int(df.loc[df.word == word][\"count_pos\"])\n",
        "  neg = int(df.loc[df.word == word][\"count_neg\"])\n",
        "  # calculate probabilities\n",
        "  p_word = (pos+neg) / (total)\n",
        "  p_word_pos = (pos)/ (total_pos)\n",
        "  p_word_neg = (neg) / (total_neg)\n",
        "\n",
        "  # print probabilities\n",
        "  # print(f\"p({word}) = {p_word}\")\n",
        "  # print(f\"p({word}|pos) = {p_word_pos}\")\n",
        "  # print(f\"p({word}|neg) = {p_word_neg}\")\n",
        "  return p_word_pos,p_pos,p_word_neg,p_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AQKE1NT9tHM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def naive(x,df):\n",
        "  res=[]\n",
        "  for sent in x:\n",
        "    predict_pos=1\n",
        "    predict_neg=1\n",
        "    p_neg=1\n",
        "    p_pos=1\n",
        "    for word in sent:\n",
        "      a,b,c,d=probability(word, df)\n",
        "      p_pos=b\n",
        "      p_neg=d\n",
        "      predict_pos=predict_pos*a\n",
        "      predict_neg=predict_neg*c\n",
        "    predict_neg=predict_neg*p_neg\n",
        "    predict_pos=predict_pos*p_pos\n",
        "    predict_pos=np.log(predict_pos)\n",
        "    predict_neg=np.log(predict_neg)\n",
        "    if(predict_pos>predict_neg):\n",
        "      res.append(1)\n",
        "    else:\n",
        "      res.append(0)\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwsPvAyjNCqv"
      },
      "outputs": [],
      "source": [
        "def accuracy(y, y_hat):\n",
        "    diff=np.array(y)-np.array(y_hat)\n",
        "    andd=np.array(y)+np.array(y_hat)\n",
        "    tp=np.sum(andd==2)\n",
        "    tn=np.sum(andd==0)\n",
        "    fp=np.sum(diff==-1)\n",
        "    fn=np.sum(diff==1)\n",
        "    print('     pos',' ','neg')\n",
        "    print(\"pos \",tp,\" \",fp)\n",
        "    print(\"neg \",fn,\"   \",tn)\n",
        "    \n",
        "    print(\"pos acc\",\"\\t\",tp/(tp+fp) )\n",
        "    print('neg acc','\\t',tn/(tn+fn) )\n",
        "    return np.mean(np.array(y)==np.array(y_hat)) #TP+TN/TP+TN+FP+FN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b03GK8Yw_DuK",
        "outputId": "f1248306-2d4b-45be-b94f-9908867ff0a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: divide by zero encountered in log\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: divide by zero encountered in log\n"
          ]
        }
      ],
      "source": [
        "imdb_train=naive(imdb_x_train,get_count_df(imdb_x_train,imdb_y_train))\n",
        "imdb_test=naive(imdb_x_test,get_count_df(imdb_x_test,imdb_y_test))\n",
        "amazon_train=naive(amazon_x_train,get_count_df(amazon_x_train,amazon_y_train))\n",
        "amazon_test=naive(amazon_x_test,get_count_df(amazon_x_test,amazon_y_test))\n",
        "yelp_train=naive(yelp_x_train,get_count_df(yelp_x_train,yelp_y_train))\n",
        "yelp_test=naive(yelp_x_test,get_count_df(yelp_x_test,yelp_y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q60OTSGUOARL",
        "outputId": "b2021f94-31b4-4145-f705-286e5eaf0904"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imdb\n",
            "     pos   neg\n",
            "pos  113   1\n",
            "neg  1     85\n",
            "pos acc \t 0.9912280701754386\n",
            "neg acc \t 0.9883720930232558\n",
            "     pos   neg\n",
            "pos  78   1\n",
            "neg  4     117\n",
            "pos acc \t 0.9873417721518988\n",
            "neg acc \t 0.9669421487603306\n",
            "\n",
            "acc \ttrain:0.99\ttest:0.975\n",
            "\n",
            "amazon\n",
            "     pos   neg\n",
            "pos  90   3\n",
            "neg  1     106\n",
            "pos acc \t 0.967741935483871\n",
            "neg acc \t 0.9906542056074766\n",
            "     pos   neg\n",
            "pos  101   2\n",
            "neg  0     97\n",
            "pos acc \t 0.9805825242718447\n",
            "neg acc \t 1.0\n",
            "\n",
            "acc \ttrain:0.98\ttest:0.99\n",
            "\n",
            "\n",
            "yelp\n",
            "     pos   neg\n",
            "pos  48   0\n",
            "neg  0     152\n",
            "pos acc \t 1.0\n",
            "neg acc \t 1.0\n",
            "     pos   neg\n",
            "pos  111   1\n",
            "neg  1     87\n",
            "pos acc \t 0.9910714285714286\n",
            "neg acc \t 0.9886363636363636\n",
            "acc \ttrain:1.0\ttest:0.99\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"imdb\")\n",
        "print(f\"\\nacc \\ttrain:{accuracy(imdb_y_train, imdb_train)}\\ttest:{accuracy(imdb_y_test, imdb_test)}\\n\")\n",
        "print(\"amazon\")\n",
        "print(f\"\\nacc \\ttrain:{accuracy(amazon_y_train, amazon_train)}\\ttest:{accuracy(amazon_y_test, amazon_test)}\\n\")\n",
        "print(\"\\nyelp\")\n",
        "print(f\"acc \\ttrain:{accuracy(yelp_y_train, yelp_train)}\\ttest:{accuracy(yelp_y_test, yelp_test)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgCGmtOnfnCR"
      },
      "outputs": [],
      "source": [
        "def prob_dict(df):\n",
        "  df[\"prob_pos\"] = df[\"count_pos\"]/(df[\"count_pos\"] + df[\"count_neg\"])\n",
        "  df[\"prob_neg\"] = df[\"count_neg\"]/(df[\"count_pos\"] + df[\"count_neg\"])\n",
        "  return df.drop(columns=[\"count_pos\", \"count_neg\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eq0maxwOaMxm",
        "outputId": "e9572c1f-79f8-4bf6-9893-06d1dbfa1a04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>prob_pos</th>\n",
              "      <th>prob_neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>film</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.239130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>movie</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.456522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>character</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>one</td>\n",
              "      <td>0.391304</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>like</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>regrettable</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>embarrass</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>exceptionally</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>intelligence</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>851</th>\n",
              "      <td>huge</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>852 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              word  prob_pos  prob_neg\n",
              "1             film  0.760870  0.239130\n",
              "42           movie  0.543478  0.456522\n",
              "93       character  0.812500  0.187500\n",
              "55             one  0.391304  0.608696\n",
              "143           like  0.500000  0.500000\n",
              "..             ...       ...       ...\n",
              "847    regrettable  0.000000  1.000000\n",
              "848      embarrass  0.000000  1.000000\n",
              "849  exceptionally  0.000000  1.000000\n",
              "850   intelligence  0.000000  1.000000\n",
              "851           huge  0.000000  1.000000\n",
              "\n",
              "[852 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>prob_pos</th>\n",
              "      <th>prob_neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>phone</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.607143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>work</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>headset</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>product</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>red</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>port</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>irda</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>answer</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>unit</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>458 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        word  prob_pos  prob_neg\n",
              "0       good  0.777778  0.222222\n",
              "18     phone  0.392857  0.607143\n",
              "1       work  0.550000  0.450000\n",
              "12   headset  1.000000  0.000000\n",
              "34   product  0.466667  0.533333\n",
              "..       ...       ...       ...\n",
              "453      red  0.000000  1.000000\n",
              "454     port  0.000000  1.000000\n",
              "455     irda  0.000000  1.000000\n",
              "456   answer  0.000000  1.000000\n",
              "457     unit  0.000000  1.000000\n",
              "\n",
              "[458 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>prob_pos</th>\n",
              "      <th>prob_neg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>great</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>place</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>service</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>good</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.444444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>love</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592</th>\n",
              "      <td>life</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>593</th>\n",
              "      <td>pour</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>594</th>\n",
              "      <td>salt</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>wind</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>draw</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>597 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        word  prob_pos  prob_neg\n",
              "59     great  1.000000  0.000000\n",
              "3      place  0.285714  0.714286\n",
              "0    service  0.350000  0.650000\n",
              "55      good  0.555556  0.444444\n",
              "29      love  0.714286  0.285714\n",
              "..       ...       ...       ...\n",
              "592     life  0.000000  1.000000\n",
              "593     pour  0.000000  1.000000\n",
              "594     salt  0.000000  1.000000\n",
              "595     wind  0.000000  1.000000\n",
              "596     draw  0.000000  1.000000\n",
              "\n",
              "[597 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "imdb = get_count_df(imdb_x_train, imdb_y_train)\n",
        "amazon=get_count_df(amazon_x_train, amazon_y_train)\n",
        "yelp=get_count_df(yelp_x_train, yelp_y_train)\n",
        "display(prob_dict(imdb))\n",
        "display(prob_dict(amazon))\n",
        "display(prob_dict(yelp))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S9PnfXwG2mQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "NaiveBayes-final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "e9487f80b5c2735bbc4afc7489ff13f77596a62e20b78908b8eb2e8fe79271a4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
